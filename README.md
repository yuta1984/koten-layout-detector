# koten-layout-detector

[English](#english) | [æ—¥æœ¬èª](#æ—¥æœ¬èª)

---

## æ—¥æœ¬èª

æ—¥æœ¬èªå¤å…¸ç±è³‡æ–™ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚ONNX Runtimeã‚’ä½¿ç”¨ã—ã€ãƒ–ãƒ©ã‚¦ã‚¶ä¸Šã§æ–‡æ›¸ç”»åƒã‹ã‚‰æœ¬æ–‡é ˜åŸŸã€å›³ç‰ˆã€å°åˆ¤ãªã©ã‚’æ¤œå‡ºã—ã¾ã™ã€‚

### ç‰¹å¾´

- ğŸ¯ æ—¥æœ¬èªå¤å…¸ç±ã«ç‰¹åŒ–ã—ãŸãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æ
- ğŸš€ ONNX Runtime Webã«ã‚ˆã‚‹ãƒ–ãƒ©ã‚¦ã‚¶ä¸Šã§ã®æ¨è«–
- ğŸ“¦ è»½é‡ã§çµ±åˆãŒå®¹æ˜“ï¼ˆç´„6KBï¼‰
- ğŸ“˜ TypeScriptå®Œå…¨å¯¾å¿œ
- ğŸ¯ 5ç¨®é¡ã®é ˜åŸŸã‚’æ¤œå‡ºï¼š
  - å…¨ä½“ï¼ˆ1_overallï¼‰
  - æ‰‹æ›¸ãï¼ˆ2_handwrittenï¼‰
  - æ´»å­—ï¼ˆ3_typographyï¼‰
  - å›³ç‰ˆï¼ˆ4_illustrationï¼‰
  - å°åˆ¤ï¼ˆ5_stampï¼‰

### ãƒ‡ãƒ¢

å®Ÿéš›ã®å‹•ä½œã¯[https://koten-layout.netlify.app/](https://koten-layout.netlify.app/)ã§ã”ç¢ºèªã„ãŸã ã‘ã¾ã™ã€‚

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
npm install koten-layout-detector onnxruntime-web
```

### ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

äº‹å‰å­¦ç¿’æ¸ˆã¿ONNXãƒ¢ãƒ‡ãƒ«ã¯GitHub ReleasesçµŒç”±ã§åˆ©ç”¨å¯èƒ½ã§ã™ï¼š

```
https://github.com/yuta1984/koten-layout-detector/releases/download/v1.1.0/best.onnx
```

æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆï¼š

```
https://github.com/yuta1984/koten-layout-detector/releases/latest/download/best.onnx
```

ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºï¼šç´„36MB

### ä½¿ã„æ–¹

```javascript
import {
  loadModel,
  preprocess,
  runInference,
  postprocess,
  drawDetections,
  CLASSES,
  COLORS
} from 'koten-layout-detector'

// GitHub Releasesã‹ã‚‰ONNXãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
const MODEL_URL = 'https://github.com/yuta1984/koten-layout-detector/releases/download/v1.1.0/best.onnx'
const session = await loadModel(MODEL_URL)

// ç”»åƒã‚’èª­ã¿è¾¼ã‚€
const img = new Image()
img.src = '/path/to/classical-document.jpg'
await img.decode()

// å‰å‡¦ç†
const { tensor, meta } = preprocess(img)

// æ¨è«–å®Ÿè¡Œ
const outputTensor = await runInference(session, tensor)

// å¾Œå‡¦ç†
const detections = postprocess(outputTensor, meta, 0.5, 0.45)

// Canvasã«æ¤œå‡ºçµæœã‚’æç”»
const canvas = document.getElementById('output-canvas')
drawDetections(canvas, img, detections)

console.log('æ¤œå‡ºã•ã‚ŒãŸé ˜åŸŸ:', detections)
```

#### TypeScript

TypeScriptã§ä½¿ç”¨ã™ã‚‹å ´åˆã€å®Œå…¨ãªå‹å®šç¾©ãŒåˆ©ç”¨ã§ãã¾ã™ï¼š

```typescript
import {
  loadModel,
  preprocess,
  runInference,
  postprocess,
  drawDetections,
  type Detection,
  type PreprocessResult,
  type ClassDefinition
} from 'koten-layout-detector'
import type { InferenceSession } from 'onnxruntime-web'

const MODEL_URL = 'https://github.com/yuta1984/koten-layout-detector/releases/download/v1.1.0/best.onnx'

// å‹å®‰å…¨ãªæ¨è«–
const session: InferenceSession = await loadModel(MODEL_URL)

const img = new Image()
img.src = '/path/to/classical-document.jpg'
await img.decode()

const { tensor, meta }: PreprocessResult = preprocess(img)
const outputTensor = await runInference(session, tensor)
const detections: Detection[] = postprocess(outputTensor, meta, 0.5, 0.45)

// å‹ãƒã‚§ãƒƒã‚¯ã•ã‚ŒãŸæ¤œå‡ºçµæœ
detections.forEach((det: Detection) => {
  console.log(`æ¤œå‡º: ${det.label} (ä¿¡é ¼åº¦: ${(det.conf * 100).toFixed(1)}%)`)
  console.log(`ä½ç½®: (${det.x1}, ${det.y1}) - (${det.x2}, ${det.y2})`)
})
```

### API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

##### `loadModel(modelUrl: string): Promise<InferenceSession>`

æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰ONNXãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

##### `preprocess(img: HTMLImageElement): { tensor: Tensor, meta: Object }`

ç”»åƒã‚’æ¨è«–ç”¨ã«å‰å‡¦ç†ã—ã¾ã™ï¼ˆãƒ¬ã‚¿ãƒ¼ãƒœãƒƒã‚¯ã‚¹ãƒªã‚µã‚¤ã‚ºï¼‰ã€‚

æˆ»ã‚Šå€¤ï¼š
- `tensor`: æ¨è«–ç”¨ã®ONNXãƒ†ãƒ³ã‚½ãƒ«
- `meta`: å¾Œå‡¦ç†ç”¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã€å…ƒç”»åƒã®å¯¸æ³•ï¼‰

##### `runInference(session: InferenceSession, tensor: Tensor): Promise<Tensor>`

å‰å‡¦ç†æ¸ˆã¿ã®ãƒ†ãƒ³ã‚½ãƒ«ã§æ¨è«–ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

##### `postprocess(outputTensor: Tensor, meta: Object, confThreshold?: number, iouThreshold?: number): Array<Detection>`

ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‚’æ¤œå‡ºçµæœã«å¤‰æ›ã—ã¾ã™ã€‚

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š
- `confThreshold`: ä¿¡é ¼åº¦é–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼š0.5ï¼‰
- `iouThreshold`: NMSã®IoUé–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼š0.45ï¼‰

æˆ»ã‚Šå€¤ã¯ä»¥ä¸‹ã‚’å«ã‚€æ¤œå‡ºçµæœã®é…åˆ—ï¼š
- `x1, y1, x2, y2`: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®åº§æ¨™
- `conf`: ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢
- `classId`: ã‚¯ãƒ©ã‚¹ID
- `label`: æ—¥æœ¬èªãƒ©ãƒ™ãƒ«
- `color`: å¯è¦–åŒ–ç”¨ã®è‰²

##### `drawDetections(canvas: HTMLCanvasElement, img: HTMLImageElement, detections: Array<Detection>): void`

å…ƒç”»åƒã¨æ¤œå‡ºãƒœãƒƒã‚¯ã‚¹ã‚’Canvasã«æç”»ã—ã¾ã™ã€‚

##### `CLASSES`

IDã€ã‚­ãƒ¼ã€æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ã‚’å«ã‚€ã‚¯ãƒ©ã‚¹å®šç¾©ã®é…åˆ—ã€‚

##### `COLORS`

å„ã‚¯ãƒ©ã‚¹ã®å¯è¦–åŒ–ç”¨ã®è‰²ã®é…åˆ—ã€‚

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€å›½ç«‹å›½ä¼šå›³æ›¸é¤¨ãŒæä¾›ã™ã‚‹[NDL-DocL ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ](https://github.com/ndl-lab/layout-dataset)ã‚’ä½¿ç”¨ã—ã¦å­¦ç¿’ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯æ—¥æœ¬èªå¤å…¸ç±ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

### ãƒ¢ãƒ‡ãƒ«

æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã¯YOLOv12ãƒ™ãƒ¼ã‚¹ã§ã€æ—¥æœ¬èªå¤å…¸ç±ã®è§£æã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚

äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯GitHub ReleasesçµŒç”±ã§åˆ©ç”¨å¯èƒ½ã§ã™ï¼ˆä¸Šè¨˜ã®[ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰](#ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰)ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‚ç…§ï¼‰ã€‚ãƒ¢ãƒ‡ãƒ«ã¯npmãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ã¯åˆ¥ã«é…å¸ƒã•ã‚Œã€ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚µã‚¤ã‚ºã‚’è»½é‡ã«ä¿ã£ã¦ã„ã¾ã™ã€‚

### ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT

### ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ­“è¿ã—ã¾ã™ï¼

### è¬è¾

- [NDL-DocL ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ](https://github.com/ndl-lab/layout-dataset) - å›½ç«‹å›½ä¼šå›³æ›¸é¤¨
- ONNX Runtime Webãƒãƒ¼ãƒ 

---

## English

Japanese classical document layout analysis library using ONNX Runtime for detecting text regions, illustrations, and stamps in historical Japanese documents.

### Features

- ğŸ¯ Specialized for Japanese classical documents (å¤å…¸ç±)
- ğŸš€ Browser-based inference using ONNX Runtime Web
- ğŸ“¦ Lightweight and easy to integrate
- ğŸ“˜ Full TypeScript support
- ğŸ¯ Detects 5 types of regions:
  - Overall layout (å…¨ä½“)
  - Handwritten text (æ‰‹æ›¸ã)
  - Typographic text (æ´»å­—)
  - Illustrations (å›³ç‰ˆ)
  - Stamps/Seals (å°åˆ¤)

### See It In Action

Check out the live demo at [https://koten-layout.netlify.app/](https://koten-layout.netlify.app/)

### Installation

```bash
npm install koten-layout-detector onnxruntime-web
```

### Model Download

The pre-trained ONNX model is available via GitHub Releases:

```
https://github.com/yuta1984/koten-layout-detector/releases/download/v1.1.0/best.onnx
```

Or use the latest version:

```
https://github.com/yuta1984/koten-layout-detector/releases/latest/download/best.onnx
```

Model size: ~36MB

### Usage

```javascript
import {
  loadModel,
  preprocess,
  runInference,
  postprocess,
  drawDetections,
  CLASSES,
  COLORS
} from 'koten-layout-detector'

// Load the ONNX model from GitHub Releases
const MODEL_URL = 'https://github.com/yuta1984/koten-layout-detector/releases/download/v1.1.0/best.onnx'
const session = await loadModel(MODEL_URL)

// Load an image
const img = new Image()
img.src = '/path/to/classical-document.jpg'
await img.decode()

// Preprocess the image
const { tensor, meta } = preprocess(img)

// Run inference
const outputTensor = await runInference(session, tensor)

// Postprocess results
const detections = postprocess(outputTensor, meta, 0.5, 0.45)

// Draw detections on canvas
const canvas = document.getElementById('output-canvas')
drawDetections(canvas, img, detections)

console.log('Detected regions:', detections)
```

#### TypeScript

Full TypeScript type definitions are available:

```typescript
import {
  loadModel,
  preprocess,
  runInference,
  postprocess,
  drawDetections,
  type Detection,
  type PreprocessResult,
  type ClassDefinition
} from 'koten-layout-detector'
import type { InferenceSession } from 'onnxruntime-web'

const MODEL_URL = 'https://github.com/yuta1984/koten-layout-detector/releases/download/v1.1.0/best.onnx'

// Type-safe inference
const session: InferenceSession = await loadModel(MODEL_URL)

const img = new Image()
img.src = '/path/to/classical-document.jpg'
await img.decode()

const { tensor, meta }: PreprocessResult = preprocess(img)
const outputTensor = await runInference(session, tensor)
const detections: Detection[] = postprocess(outputTensor, meta, 0.5, 0.45)

// Type-checked detection results
detections.forEach((det: Detection) => {
  console.log(`Detected: ${det.label} (confidence: ${(det.conf * 100).toFixed(1)}%)`)
  console.log(`Position: (${det.x1}, ${det.y1}) - (${det.x2}, ${det.y2})`)
})
```

### API Reference

##### `loadModel(modelUrl: string): Promise<InferenceSession>`

Loads an ONNX model from the specified URL.

#### `preprocess(img: HTMLImageElement): { tensor: Tensor, meta: Object }`

Preprocesses an image for inference with letterbox resizing.

Returns:
- `tensor`: ONNX tensor ready for inference
- `meta`: Metadata for postprocessing (scale, padding, original dimensions)

#### `runInference(session: InferenceSession, tensor: Tensor): Promise<Tensor>`

Runs inference on the preprocessed tensor.

#### `postprocess(outputTensor: Tensor, meta: Object, confThreshold?: number, iouThreshold?: number): Array<Detection>`

Postprocesses the model output into detection results.

Parameters:
- `confThreshold`: Confidence threshold (default: 0.5)
- `iouThreshold`: IoU threshold for NMS (default: 0.45)

Returns an array of detections with:
- `x1, y1, x2, y2`: Bounding box coordinates
- `conf`: Confidence score
- `classId`: Class ID
- `label`: Japanese label
- `color`: Color for visualization

#### `drawDetections(canvas: HTMLCanvasElement, img: HTMLImageElement, detections: Array<Detection>): void`

Draws the original image and detection boxes on a canvas.

#### `CLASSES`

Array of class definitions with ID, key, and Japanese labels.

#### `COLORS`

Array of colors for each class for visualization.

### Dataset

This model is trained on the [NDL-DocL Layout Dataset](https://github.com/ndl-lab/layout-dataset) provided by the National Diet Library of Japan. The dataset contains annotated layout information for Japanese classical documents.

### Model

The detection model is based on YOLOv12, optimized for classical Japanese document analysis.

The pre-trained model is available via GitHub Releases (see [Model Download](#model-download) section above). The model is distributed separately from the npm package to keep the package lightweight.

### License

MIT

### Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

### Acknowledgments

- [NDL-DocL Layout Dataset](https://github.com/ndl-lab/layout-dataset) - National Diet Library of Japan
- ONNX Runtime Web team for the excellent inference engine
